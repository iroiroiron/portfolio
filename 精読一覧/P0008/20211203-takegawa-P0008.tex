%フォーマット更新日：20210728
%
%

\documentclass[10pt,onecolumn]{jsarticle}

\usepackage[dvipdfmx]{graphicx}
\usepackage{multirow}
\usepackage{url}
\usepackage{otf}
\usepackage{here}
\usepackage{bm}
\usepackage{amsmath}
\usepackage{algorithmic}
\usepackage{algorithm}

\renewcommand{\refname}{次に読むべき論文のリスト}


\newcommand{\hama}{\ajMayuHama}


\pagestyle{empty}

\setlength{\topmargin}{6mm}
\setlength{\oddsidemargin}{-4mm}
\setlength{\evensidemargin}{-4mm}
\setlength{\textwidth}{175mm}
\setlength{\headsep}{0pt}
\setlength{\headheight}{0pt}
\setlength{\textheight}{235mm}
\setlength{\columnsep}{5mm}

\begin{document}

%\twocolumn[%
\vspace{-20mm}
\begin{center}
{\LARGE\textbf{論文メモ}}
\end{center}

\begin{flushright}
\begin{tabular}{|c|l|}
%\hline
%版数  &   0001からはじめる
%\\
\hline
文献番号  &  0009
\\
\hline
日付  &  2021年12月05日
\\
\hline
名前  &  武川海斗
\\
\hline
\end{tabular}
\end{flushright}
%]

%--------------
%本文開始
%--------------

%-------------------------------------------------------------------------
%\section*{論文情報}
%-------------------------------------------------------------------------
%
%論文の基本情報についてまとめる
%
\begin{center}
{\large 文献情報}
\begin{table}[hbp]%[H]
\begin{tabular}{|l||l|}
\hline
著者  & Anil K. Jain
\\ \hline
英文タイトル  & Data clustering: 50 years beyond K-means
\\ \hline
和文タイトル  & データクラスタリング: 50年後のK-means
\\ \hline
書誌情報  &  Pattern Recognition Letters, ELSEVIER, Vol.~31, pp.~651--pp.~666, 2010
\\ \hline
キーワード & Data clustering,User’s dilemma ,Historical developments, Perspectives on clustering
\\ \hline
\end{tabular}
\end{table}
\end{center}

\section{論文の要約}
本論文では，クラスタリングの歴史，手法，問題点，動向について俯瞰的にまとめた論文である．そして最後の結びとして，クラスタリングの注目すべき問題と研究の方向性について示している．
データが複雑化する現代では，クラスタリングの需要が高まることは驚くべきことではない．ここで重要となるのは，クラスタリングは利用者に対して，仮説を考えるためのヒントを与えるモノでしかないということである．
また，完璧なクラスタリング結果を求めるための最良なクラスタリングアルゴリズムは存在しない．それは，クラスタリングアルゴリズムは，クラスタ構造を求めるためのものであり，そこに価値を見出すのは我々だからである．クラスタリング結果をどう表現し，把握するのかは重要なトピックとなる．

ここで注意すべきことは，本論文は2010年時点でのクラスタリングの研究動向，歴史をまとめたものであるということである．クラスタリングの研究手法は年々増えており，自分自身で最新の研究手法を追いかけることが必要となる．

\section{手法の動向}
\subsection{半教師付きクラスタリング}
クラスタリングとは本質的に，与えられたデータのみの情報からクラスタ分割を行う．そこで，半教師付きクラスタリングでは，側面的な情報を与えることで，より正確なクラスタリングを行う．ここで，「側面的な情報」として，ペアワイズ制約が一般的である．この制約知識にはデー タペアが同じクラスに属するか否かという情報が用いられ，前者はmust-link，後者をcannot-linkと呼ばれる．実際の半教師付きクラスタリングのアプローチも，既存のクラスタリングの目的関数にペアワイズ制約を加えたものが大半である．

\subsection{クラスタリングアンサンブル}
教師あり学習における「アンサンブル学習」をクラスタリングに適応した手法である．具体的には，同一のデータに対して，クラスタ数Kなどの初期値やアルゴリズムを変えた手法をクラスタリングした結果を組み合わせること(多数決)で，良好な分割結果を得られるというものである．ただし，これにはクラスタ結果を評価するための妥当性基準が必要である．

\section{今後の課題}
この節では，クラスタリングにおける問題点，今後の課題についていくつか取り上げてまとめる．
\subsection{分割結果の可視化}
クラスタリング結果を表現することは難しい．例えば，四次元のデータをクラスタリングした場合，クラスタリング結果をどのように表現すれば良いだろうか？我々は三次元データまでしか認識することはできず，不可能な問題である．そのため，クラスタリング結果は二次元でプロットされることが多い．そのため，特徴量の選択はユーザーの選択に依存することになる．これがユーザーにとって難しく，データに対するドメイン知識(専門知識)が必要になるため，問題となっているのである．
\subsection{クラスタ数}
クラスタ数の自動推定は，最も困難な問題の一つである．K-Meansなどの手法では，クラスタ数を事前に与え，パラメータとしてクラスタリングを行う．しかし，未知のデータをクラスタリングを行う場合，事前にクラスタ数がわからない場合はほとんどである．そこで，クラスタ数を自動に推定することが重要となる．
\subsection{クラスタの妥当性基準}
クラスタの妥当性とは，クラスタリングの結果を定量的かつ客観的に評価する指標のことである．一般にクラスタリング結果の有効性を確かめることは難しい．教師あり学習と異なり，正解ラベルが存在しないからである．

クラスタの妥当性基準は内部，相対，外部の三つの異なる基準に基づいている．内部基準に基づく妥当性基準はクラスタ構造とデータの関係(分散や類似度など)を用いてクラスタリングがうまく行えているかを確かめるものである．次に，相対基準とは，異なるアルゴリズム間を比較し，どういったデータでは優れているのかを分類する．最後に，外部基準とは正解ラベル等を照合することで性能を測定する．しかし，正解ラベルを得られるのであれば，クラスタリングなど必要ないのではないかといった主張を著者はしている．
妥当性基準を用いて，クロスバリエーションを行うことで，クラスタ数の推定を行うことができる．そのため，良質な妥当性基準が開発されることはクラスタ数決定の問題を解決することにも繋がるため，重要なトピックであると言える．


%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
\end{document}
